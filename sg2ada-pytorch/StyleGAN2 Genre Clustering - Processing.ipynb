{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea9685bf",
   "metadata": {},
   "source": [
    "# Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb7ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/dvschultz/stylegan2-ada-pytorch dvschultz-stylegan2-ada-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbcb312",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd dvschultz-stylegan2-ada-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f41180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster files\n",
    "!gdown --id 17eGxxtT_DdKD4WotgJfXf8IGA9_cXAiH\n",
    "!unzip StyleGAN2_Genre_Clustering-20210719T132300Z-001.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052aca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "!gdown --id 14896oHvNWYsxQvbrJiah8H9srown10wW\n",
    "!mv network-snapshot-000192.pkl stylegan2-ada-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbf8f07",
   "metadata": {},
   "source": [
    "# ðŸ Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3dd69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83c5111",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e32073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd dvschultz-stylegan2-ada-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd0206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import math\n",
    "import shutil\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import PIL.Image\n",
    "from tqdm.autonotebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "import dnnlib\n",
    "import legacy\n",
    "import imageio\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0d6173",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'StyleGAN2_Genre_Clustering'\n",
    "prefix = 'flowers_v3'\n",
    "suffix = '64cat_65536s_123seed_1psi_const'\n",
    "ws = np.load(f\"{folder}/{prefix}_latents_ws_{suffix}.npy\")\n",
    "zs = np.load(f\"{folder}/{prefix}_latents_zs_{suffix}.npy\")\n",
    "cluster_avg = np.load(f\"{folder}/{prefix}_cluster_avg_{suffix}.npy\")\n",
    "cluster_labels = np.load(f\"{folder}/{prefix}_cluster_labels_{suffix}.npy\")\n",
    "print(ws.shape, zs.shape, cluster_avg.shape, cluster_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e1e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = f'{folder}/clusters'\n",
    "network_pkl = 'network-snapshot-000192.pkl'\n",
    "\n",
    "# Number of image to render per cluster\n",
    "# ---\n",
    "# Some small number of images (2, 3, 5, 6) throw some errors when generating a small batch with G.synthesis(), \n",
    "# No idea why, it might come from multi GPU support, \n",
    "# If you have error in the main generate loop just try a different number ;)\n",
    "img_count = 4\n",
    "clusters_count = cluster_labels.max()+1\n",
    "# Noise mode needs to be the same than the one used while creating the clusters\n",
    "truncation_psi = 1\n",
    "# 'const', 'random', 'none'\n",
    "noise_mode = 'const'\n",
    "# Video output number of frame\n",
    "fps = 25\n",
    "frame_count = fps * 24\n",
    "# Batch size for img generation\n",
    "# Better if frame_count is a MULTIPLE of batch_size if possible\n",
    "batch_size = 80\n",
    "# For style mixing\n",
    "style_layer_range = [9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
    "\n",
    "# Settings per animation's type \n",
    "circ_settings = {'start':0.5, 'radius':80}\n",
    "lsj_settings = {'start':0.5, 'radius':80, 'abc':(1, 2, 2)}\n",
    "slerp_settings = {'start':0}\n",
    "trunc_settings = {'positive':4, 'negative':12}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "image_mean = torch.tensor([0.48145466, 0.4578275, 0.40821073]).to(device)\n",
    "image_std = torch.tensor([0.26862954, 0.26130258, 0.27577711]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21133baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_movie(fn, imgs, fps):\n",
    "    with imageio.get_writer(fn, format='FFMPEG', codec='h264', fps=fps) as w:\n",
    "        for img in imgs:\n",
    "            w.append_data(np.array(img))\n",
    "\n",
    "\n",
    "# noise_mode = 'const', 'random', 'none'\n",
    "def generate_images_from_zs(G, latents, labels, batch_size, truncation_psi=1, noise_mode='const', truncation_cutoff=None):\n",
    "    all_imgs = []\n",
    "    r = math.ceil(latents.shape[0]/batch_size)\n",
    "    for i in tqdm(range(r)):\n",
    "        zs = latents[i*batch_size:min((i+1)*batch_size, latents.shape[0]), :]\n",
    "        imgs = G(zs, labels, truncation_psi=truncation_psi, truncation_cutoff=truncation_cutoff, noise_mode=noise_mode)\n",
    "        imgs = (imgs.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
    "        for j in range(imgs.shape[0]):\n",
    "            img = imgs[j].cpu().numpy()\n",
    "            all_imgs.append(PIL.Image.fromarray(img, 'RGB'))\n",
    "    return all_imgs\n",
    "\n",
    "\n",
    "# noise_mode = 'const', 'random', 'none'\n",
    "def generate_images_from_ws(G, latents, batch_size, truncation_psi=1, noise_mode='const'):\n",
    "    all_imgs = []\n",
    "    r = math.ceil(latents.shape[0]/batch_size)\n",
    "    for i in tqdm(range(r)):\n",
    "        ws = latents[i*batch_size:min((i+1)*batch_size, latents.shape[0]), :]\n",
    "        w_avg = G.mapping.w_avg\n",
    "        ws = w_avg + (ws - w_avg) * truncation_psi\n",
    "        imgs = G.synthesis(ws, noise_mode=noise_mode)\n",
    "        imgs = (imgs.clamp(-1, 1).permute(0, 2, 3, 1).cpu().numpy() * 127.5 + 128).astype(np.uint8)\n",
    "        for j in range(imgs.shape[0]):\n",
    "            all_imgs.append(PIL.Image.fromarray(imgs[j]))\n",
    "    return all_imgs\n",
    "\n",
    "\n",
    "def image_grid(images, rows, cols):\n",
    "    assert len(images) == rows*cols\n",
    "    print(images[0])\n",
    "    w, h = images[0].size\n",
    "    grid = PIL.Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(images):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid\n",
    "\n",
    "\n",
    "# Circular\n",
    "def circ_interpolation(radius, lats_persistent, lats_interpolate):\n",
    "    lats_a, lats_b, lats_c = lats_persistent\n",
    "\n",
    "    lats_axis_x = (lats_a - lats_b).flatten() / np.linalg.norm(lats_a - lats_b)\n",
    "    lats_axis_y = (lats_a - lats_c).flatten() / np.linalg.norm(lats_a - lats_c)\n",
    "\n",
    "    lats_x = np.sin(np.pi * 2.0 * lats_interpolate) * radius\n",
    "    lats_y = np.cos(np.pi * 2.0 * lats_interpolate) * radius - radius\n",
    "    \n",
    "    latents = lats_a + lats_x * lats_axis_x + lats_y * lats_axis_y\n",
    "    return latents\n",
    "\n",
    "\n",
    "# Lisajou\n",
    "def lsj_interpolation(radius, lats_persistent, a, b, c, lats_interpolate):\n",
    "    lats_a, lats_b, lats_c, lats_d = lats_persistent\n",
    "\n",
    "    lats_axis_x = (lats_a - lats_b).flatten() / np.linalg.norm(lats_a - lats_b)\n",
    "    lats_axis_y = (lats_a - lats_c).flatten() / np.linalg.norm(lats_a - lats_c)\n",
    "    lats_axis_z = (lats_a - lats_d).flatten() / np.linalg.norm(lats_a - lats_d)\n",
    "\n",
    "    lats_x = np.sin(np.pi * 2.0 * lats_interpolate * a) * radius\n",
    "    lats_y = np.sin(np.pi * 2.0 * lats_interpolate * b) * radius\n",
    "    lats_z = np.sin(np.pi * 2.0 * lats_interpolate * c) * radius\n",
    "    \n",
    "    latents = np.copy(lats_a)\n",
    "    latents[0, 0::3] += lats_x * lats_axis_x[::3]\n",
    "    latents[0, 1::3] += lats_y * lats_axis_x[1::3]\n",
    "    latents[0, 2::3] += lats_z * lats_axis_z[2::3]\n",
    "    \n",
    "    return latents\n",
    "\n",
    "\n",
    "# slightly modified version of\n",
    "# https://github.com/PDillis/stylegan2-fun/blob/master/run_generator.py#L399\n",
    "def slerp(t, v0, v1, DOT_THRESHOLD=0.9995):\n",
    "    '''\n",
    "    Spherical linear interpolation\n",
    "    Args:\n",
    "        t (float/np.ndarray): Float value between 0.0 and 1.0\n",
    "        v0 (np.ndarray): Starting vector\n",
    "        v1 (np.ndarray): Final vector\n",
    "        DOT_THRESHOLD (float): Threshold for considering the two vectors as\n",
    "                               colineal. Not recommended to alter this.\n",
    "    Returns:\n",
    "        v2 (np.ndarray): Interpolation vector between v0 and v1\n",
    "    '''\n",
    "    # Copy the vectors to reuse them later\n",
    "    v0_copy = np.copy(v0)\n",
    "    v1_copy = np.copy(v1)\n",
    "    # Normalize the vectors to get the directions and angles\n",
    "    v0 = v0 / np.linalg.norm(v0)\n",
    "    v1 = v1 / np.linalg.norm(v1)\n",
    "    # Dot product with the normalized vectors (can't use np.dot in W)\n",
    "    dot = np.sum(v0 * v1)\n",
    "    # If absolute value of dot product is almost 1, vectors are ~colineal, so use lerp\n",
    "    if np.abs(dot) > DOT_THRESHOLD:\n",
    "        return lerp(t, v0_copy, v1_copy)\n",
    "    # Calculate initial angle between v0 and v1\n",
    "    theta_0 = np.arccos(dot)\n",
    "    sin_theta_0 = np.sin(theta_0)\n",
    "    # Angle at timestep t\n",
    "    theta_t = theta_0 * t\n",
    "    sin_theta_t = np.sin(theta_t)\n",
    "    # Finish the slerp algorithm\n",
    "    s0 = np.sin(theta_0 - theta_t) / sin_theta_0\n",
    "    s1 = sin_theta_t / sin_theta_0\n",
    "    v2 = s0 * v0_copy + s1 * v1_copy\n",
    "    return v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e244397",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dnnlib.util.open_url(network_pkl) as f:\n",
    "    G = legacy.load_network_pkl(f)['G_ema'].requires_grad_(False)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        G.synthesis = torch.nn.DataParallel(G.synthesis)\n",
    "    G = G.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec12ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ws and zs to tensors\n",
    "# if isinstance(ws, np.ndarray):\n",
    "#     ws = np.expand_dims(ws, axis=1)\n",
    "#     ws = np.tile(ws, [1, G.module.mapping.num_ws, 1])\n",
    "#     ws = torch.tensor(ws, dtype=torch.float32, device=device)\n",
    "# if isinstance(zs, np.ndarray):\n",
    "#     zs = torch.tensor(zs, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f97f418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear dir\n",
    "# shutil.rmtree(f'{outdir}/{prefix}_{suffix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca51798",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate\n",
    "# all_imgs = []\n",
    "\n",
    "# Main dir\n",
    "os.makedirs(f'{outdir}/{prefix}_{suffix}', exist_ok=True)\n",
    "\n",
    "for i in range(clusters_count):\n",
    "\n",
    "    # Mask latents array using cluster_labels\n",
    "    ws_cluster = ws[cluster_labels==i][:img_count]\n",
    "    zs_cluster = zs[cluster_labels==i][:img_count]\n",
    "    \n",
    "    # Convert to Tensors\n",
    "    if isinstance(ws_cluster, np.ndarray):\n",
    "        ws_cluster = np.expand_dims(ws_cluster, axis=1)\n",
    "        ws_cluster = np.tile(ws_cluster, [1, G.mapping.num_ws, 1])\n",
    "        ws_cluster = torch.tensor(ws_cluster, dtype=torch.float32, device=device)\n",
    "    if isinstance(zs_cluster, np.ndarray):\n",
    "        zs_cluster = torch.tensor(zs_cluster, dtype=torch.float32, device=device)\n",
    "\n",
    "    print(f'> Cluster {i}: {ws_cluster.shape[0]} imgs (saving {img_count}, trunc_psi:{truncation_psi}, noise_mode:{noise_mode})')\n",
    "    \n",
    "    print(ws_cluster.shape, img_count, truncation_psi, noise_mode)\n",
    "    imgs = generate_images_from_ws(G, ws_cluster, batch_size, truncation_psi, noise_mode)\n",
    "    # all_imgs.append(imgs)\n",
    "\n",
    "    # Save imgs + npz + vids\n",
    "    os.makedirs(f'{outdir}/{prefix}_{suffix}/{i}', exist_ok=True)\n",
    "    \n",
    "    for j, (img, w, z) in enumerate(zip(imgs, ws_cluster, zs_cluster)):        \n",
    "        \n",
    "        os.makedirs(f'{outdir}/{prefix}_{suffix}/{i}/{j}', exist_ok=True)\n",
    "        \n",
    "        print(f'-> {outdir}/{i}/{j} Saving')\n",
    "        t1 = time.time()\n",
    "        \n",
    "        img.save(f\"{outdir}/{prefix}_{suffix}/{i}/{j}/img.jpg\")\n",
    "        np.savez(f'{outdir}/{prefix}_{suffix}/{i}/{j}/w.npz', w=w.unsqueeze(0).cpu().numpy())\n",
    "        np.savez(f'{outdir}/{prefix}_{suffix}/{i}/{j}/z.npz', z=z.unsqueeze(0).cpu().numpy())\n",
    "        \n",
    "        random_seeds = np.random.randint(0, 1000, 3)\n",
    "                \n",
    "        z = z.unsqueeze(0).cpu().numpy()\n",
    "        z1 = z + (np.random.RandomState(random_seeds[0]).randn(1, 512)-.5)\n",
    "        z2 = z + (np.random.RandomState(random_seeds[1]).randn(1, 512)-.5)\n",
    "        z3 = z + (np.random.RandomState(random_seeds[2]).randn(1, 512)-.5)\n",
    "        \n",
    "        labels = torch.zeros([frame_count, G.c_dim], device=device)\n",
    "\n",
    "        # Circular interpolation\n",
    "        start, radius = circ_settings.values()\n",
    "        print(f\"--> Circular interpolation start:{start} radius:{radius} random-seeds:{random_seeds[:2]}\")\n",
    "        circ_zs = [circ_interpolation(radius, (z, z1, z2), start+(i/frame_count)*(1-start)) for i in range(1, frame_count+1)]\n",
    "        circ_zs = torch.from_numpy(np.array(circ_zs)[:,0,:]).to(device)\n",
    "        circ_imgs = generate_images_from_zs(G, circ_zs, labels, batch_size, truncation_psi)\n",
    "        circ_fn = f\"circ_start_{str(start).replace('.', ',')}_radius_{radius}_random-seeds{random_seeds[:2].tolist()}\"\n",
    "        make_movie(f\"{outdir}/{prefix}_{suffix}/{i}/{j}/{circ_fn}.mp4\", circ_imgs, fps)\n",
    "        circ_ws_clone = G.mapping(circ_zs, None).detach().clone()\n",
    "        del circ_zs , circ_imgs\n",
    "        \n",
    "        # Lisajou interpolation\n",
    "        start, radius, (a, b, c) = lsj_settings.values()\n",
    "        print(f\"--> Lisajou interpolation start:{start} radius:{radius} random-seeds:{random_seeds} abc:{(a,b,c)}\")\n",
    "        lsj_zs = [lsj_interpolation(radius, (z, z1, z2, z3), a, b, c, start+(i/frame_count)*(1-start)) for i in range(1, frame_count+1)]\n",
    "        lsj_zs = np.array(lsj_zs)[:,0,:]\n",
    "        lsj_zs = lsj_zs[::-1].copy()\n",
    "        lsj_zs = torch.from_numpy(lsj_zs).to(device)\n",
    "        lsj_imgs = generate_images_from_zs(G, lsj_zs, labels, batch_size, truncation_psi)\n",
    "        lsj_fn = f\"lsj_start_{str(start).replace('.', ',')}_radius_{radius}_random-seeds{random_seeds.tolist()}_a_{a}_b_{b}_c_{c}\"\n",
    "        make_movie(f\"{outdir}/{prefix}_{suffix}/{i}/{j}/{lsj_fn}.mp4\", lsj_imgs, fps)\n",
    "        lsj_ws_clone = G.mapping(lsj_zs, None).detach().clone()\n",
    "        del lsj_zs, lsj_imgs\n",
    "        \n",
    "        # Slerp\n",
    "        start = slerp_settings['start']\n",
    "        print(f\"--> Slerp interpolation start:{start} random-seed:{random_seeds[0]}\")\n",
    "        slerp_zs = [slerp(start+(i/frame_count)*(1-start), z1, z) for i in range(1, frame_count+1)]\n",
    "        slerp_zs = torch.from_numpy(np.array(slerp_zs)[:,0,:]).to(device)\n",
    "        slerp_imgs = generate_images_from_zs(G, slerp_zs, labels, batch_size, truncation_psi)\n",
    "        slerp_fn = f\"slerp_start_{str(start).replace('.', ',')}_random-seeds[{random_seeds[0]}]\"\n",
    "        make_movie(f\"{outdir}/{prefix}_{suffix}/{i}/{j}/{slerp_fn}.mp4\", slerp_imgs, fps)\n",
    "        slerp_ws_clone = G.mapping(slerp_zs, None).detach().clone()\n",
    "        del slerp_zs, slerp_imgs\n",
    "        \n",
    "        # Truncation\n",
    "        pos, neg = trunc_settings.values()\n",
    "        z = torch.from_numpy(z).to(device)\n",
    "        print(f\"--> Truncation interpolation positive:+{pos} negative:-{neg}\")\n",
    "        \n",
    "        # Positive\n",
    "        # https://github.com/pytorch/pytorch/issues/31460\n",
    "        trunc_pos_ws = [G.mapping(z, None, truncation_psi=truncation_psi+(i/frame_count)*pos).cpu().numpy() for i in range(1, frame_count+1)]\n",
    "        trunc_pos_ws = torch.from_numpy(np.array(trunc_pos_ws)[:,0,:]).to(device)\n",
    "        trunc_pos_imgs = generate_images_from_ws(G, trunc_pos_ws, batch_size)\n",
    "        trunc_pos_fn = f\"trunc_pos_{pos}\"\n",
    "        make_movie(f\"{outdir}/{prefix}_{suffix}/{i}/{j}/{trunc_pos_fn}.mp4\", trunc_pos_imgs, fps)\n",
    "        trunc_pos_ws_clone = trunc_pos_ws.detach().clone()\n",
    "        del trunc_pos_ws, trunc_pos_imgs\n",
    "        \n",
    "        # Negative\n",
    "        trunc_neg_ws = [G.mapping(z, None, truncation_psi=truncation_psi-(i/frame_count)*neg).cpu().numpy() for i in range(1, frame_count+1)]\n",
    "        trunc_neg_ws = torch.from_numpy(np.array(trunc_neg_ws)[:,0,:]).to(device)\n",
    "        trunc_neg_imgs = generate_images_from_ws(G, trunc_neg_ws, batch_size)\n",
    "        trunc_neg_fn = f\"trunc_neg_{neg}\"\n",
    "        make_movie(f\"{outdir}/{prefix}_{suffix}/{i}/{j}/{trunc_neg_fn}.mp4\", trunc_neg_imgs, fps)\n",
    "        trunc_neg_ws_clone = trunc_neg_ws.detach().clone()\n",
    "        del trunc_neg_ws, trunc_neg_imgs\n",
    "        \n",
    "        # Style mixing (sm)\n",
    "        for file in glob.iglob(f'{outdir}/style_transfer_seeds/*.npy'):\n",
    "            \n",
    "            npy_fn = file.split('/')[-1].split('.')[0]\n",
    "            print(f'--> Style Mixing {npy_fn}')\n",
    "            \n",
    "            style_z = torch.from_numpy(np.load(file)).to(device)\n",
    "            style_w = G.mapping(style_z, None)\n",
    "\n",
    "            print(f'---> Circular interpolation')\n",
    "            circ_ws_clone[:,style_layer_range,:] = style_w[0][style_layer_range]\n",
    "            circ_imgs_sm = generate_images_from_ws(G, circ_ws_clone, batch_size, truncation_psi)\n",
    "            make_movie(f\"{outdir}/{prefix}_{suffix}/{i}/{j}/{circ_fn}_sm_{npy_fn}.mp4\", circ_imgs_sm, fps)\n",
    "            del circ_imgs_sm\n",
    "\n",
    "            print(f'---> Lisajou interpolation')\n",
    "            lsj_ws_clone[:,style_layer_range,:] = style_w[0][style_layer_range]\n",
    "            lsj_imgs_sm = generate_images_from_ws(G, lsj_ws_clone, batch_size, truncation_psi)\n",
    "            make_movie(f\"{outdir}/{prefix}_{suffix}/{i}/{j}/{lsj_fn}_sm_{npy_fn}.mp4\", lsj_imgs_sm, fps)\n",
    "            del lsj_imgs_sm\n",
    "\n",
    "            print(f'---> Lerp interpolation')\n",
    "            slerp_ws_clone[:,style_layer_range,:] = style_w[0][style_layer_range]\n",
    "            slerp_imgs_sm = generate_images_from_ws(G, slerp_ws_clone, batch_size, truncation_psi)\n",
    "            make_movie(f\"{outdir}/{prefix}_{suffix}/{i}/{j}/{slerp_fn}_sm_{npy_fn}.mp4\", slerp_imgs_sm, fps)\n",
    "            del slerp_imgs_sm\n",
    "\n",
    "            print(f'---> Trunc positive')\n",
    "            trunc_pos_ws_clone[:,style_layer_range,:] = style_w[0][style_layer_range]\n",
    "            trunc_pos_imgs_sm = generate_images_from_ws(G, trunc_pos_ws_clone, batch_size, truncation_psi)\n",
    "            make_movie(f\"{outdir}/{prefix}_{suffix}/{i}/{j}/{trunc_pos_fn}_sm_{npy_fn}.mp4\", trunc_pos_imgs_sm, fps)\n",
    "            del trunc_pos_imgs_sm\n",
    "\n",
    "            print(f'---> Trunc negative')\n",
    "            trunc_neg_ws_clone[:,style_layer_range,:] = style_w[0][style_layer_range]\n",
    "            trunc_neg_imgs_sm = generate_images_from_ws(G, trunc_neg_ws_clone, batch_size, truncation_psi)\n",
    "            make_movie(f\"{outdir}/{prefix}_{suffix}/{i}/{j}/{trunc_neg_fn}_sm_{npy_fn}.mp4\", trunc_neg_imgs_sm, fps)\n",
    "            del trunc_neg_imgs_sm\n",
    "        \n",
    "        # Clean some shit\n",
    "        del circ_ws_clone, lsj_ws_clone, slerp_ws_clone, trunc_pos_ws_clone, trunc_neg_ws_clone\n",
    "\n",
    "        print(f'-> {outdir}/{i}/{j} Saved in {timedelta(seconds=time.time()-t1)}\\n---')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330fc1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save images\n",
    "img_save_count = batch_size*10\n",
    "\n",
    "# Main dir\n",
    "os.makedirs(f'{outdir}/{prefix}_{suffix}', exist_ok=True)\n",
    "\n",
    "for i in range(clusters_count):\n",
    "\n",
    "    # Mask latents array using cluster_labels\n",
    "    ws_cluster = ws[cluster_labels==i]\n",
    "    ws_cluster = ws_cluster[:min(img_save_count, ws_cluster.shape[0])]\n",
    "    \n",
    "    # Convert to Tensors\n",
    "    if isinstance(ws_cluster, np.ndarray):\n",
    "        ws_cluster = np.expand_dims(ws_cluster, axis=1)\n",
    "        ws_cluster = np.tile(ws_cluster, [1, G.mapping.num_ws, 1])\n",
    "        ws_cluster = torch.tensor(ws_cluster, dtype=torch.float32, device=device)\n",
    "\n",
    "    print(f'> Cluster {i}: {ws_cluster.shape[0]} imgs (saving {ws_cluster.shape[0]}, trunc_psi:{truncation_psi}, noise_mode:{noise_mode})')\n",
    "    \n",
    "    imgs = generate_images_from_ws(G, ws_cluster, batch_size, truncation_psi, noise_mode)\n",
    "\n",
    "    # Save imgs + npz + vids\n",
    "    os.makedirs(f'{outdir}/{prefix}_{suffix}/{i}', exist_ok=True)\n",
    "\n",
    "    t1 = time.time()\n",
    "    \n",
    "    for j, img in tqdm(enumerate(imgs)):\n",
    "        img.save(f\"{outdir}/{prefix}_{suffix}/{i}/{j}.jpg\")\n",
    "\n",
    "    print(f'-> {outdir}/{i} Saved in {timedelta(seconds=time.time()-t1)}\\n---')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e71e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# circular_ws_clone[:,style_layer_range,:] = style_w[0][style_layer_range]\n",
    "# circular_imgs_sm = generate_images_from_ws(G, circular_ws_clone, batch_size, truncation_psi)\n",
    "display(image_grid(circular_imgs_sm[16:32], 4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95454fe1",
   "metadata": {},
   "source": [
    "---\n",
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c28b83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All images from ws\n",
    "all_imgs = []\n",
    "# Batch size\n",
    "bs = 7\n",
    "for i in range(2):\n",
    "    # Mask latents array using cluster_labels\n",
    "    ws_cluster = ws[cluster_labels==i][:bs]\n",
    "    if isinstance(ws_cluster, np.ndarray):\n",
    "        ws_cluster = np.expand_dims(ws_cluster, axis=1)\n",
    "        ws_cluster = np.tile(ws_cluster, [1, G.mapping.num_ws, 1])\n",
    "        ws_cluster = torch.tensor(ws_cluster, dtype=torch.float32, device=device)\n",
    "    print(ws_cluster.shape, bs)\n",
    "    imgs = generate_images_from_ws(G, ws_cluster, bs)\n",
    "    print(len(imgs))\n",
    "    all_imgs.append(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b11eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All images from zs\n",
    "all_imgs = []\n",
    "# Batch size\n",
    "bs = 40 \n",
    "for i in range(2):\n",
    "    # Mask latents array using cluster_labels\n",
    "    zs_cluster = zs[cluster_labels==i][:bs*15]\n",
    "    if isinstance(zs_cluster, np.ndarray):\n",
    "        zs_cluster = torch.tensor(zs_cluster, dtype=torch.float32, device=device)\n",
    "    labels = torch.zeros([zs_cluster.shape[0], G.c_dim], device=device)\n",
    "    print(zs_cluster.shape, labels.shape, bs)\n",
    "    imgs = generate_images_from_zs(G, zs_cluster, labels, bs)\n",
    "    print(len(imgs))\n",
    "    all_imgs.append(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fe1f96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for imgs in all_imgs:\n",
    "    display(image_grid(imgs, 10, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469926ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_z = np.load(f'{outdir}/{prefix}_{suffix}/0/0_z.npz')['z']\n",
    "b_z = a_z + (np.random.RandomState(442).randn(1, 512)-.5)\n",
    "c_z = a_z + (np.random.RandomState(353).randn(1, 512)-.5)\n",
    "d_z = a_z + (np.random.RandomState(random_seeds[2]).randn(1, 512)-.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec1088",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start, radius = circ_settings.values()\n",
    "frame_count = 576\n",
    "zs = [circ_interpolation(radius, (a_z, b_z, c_z), start+(i/frame_count)*(1-start)) for i in range(1, frame_count+1)]\n",
    "print(len(zs))\n",
    "zs = np.array(zs)[:,0,:]\n",
    "zs = torch.from_numpy(zs).to(device)\n",
    "labels = torch.zeros([zs.shape[0], G.c_dim], device=device)\n",
    "\n",
    "imgs = generate_images_from_zs(G, zs, labels, batch_size, truncation_psi)\n",
    "\n",
    "fn = 'test.mp4'\n",
    "make_movie(fn, imgs, fps)\n",
    "Video(fn, embed=True, width=800, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e49fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = [lisajou_interpolation(radius, (a_z, b_z, c_z, d_z), 1, 2, 2, start+(i/frame_count)*(1-start)) for i in range(frame_count)]\n",
    "\n",
    "zs = np.array(zs)[:,0,:]\n",
    "zs = torch.from_numpy(zs).to(device)\n",
    "labels = torch.zeros([zs.shape[0], G.c_dim], device=device)\n",
    "\n",
    "imgs = generate_images_from_zs(G, zs, labels, batch_size, truncation_psi)\n",
    "\n",
    "fn = f\"lisajou_start_{str(start).replace('.', ',')}_radius_{radius}_random-seeds{random_seeds.tolist()}.mp4\"\n",
    "make_movie(fn, imgs, fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941917aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(fn, embed=True, width=800, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718f36fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncation\n",
    "# a_z = torch.from_numpy(a_z).to(device)\n",
    "# a_w = G.mapping(a_z, None, truncation_psi=truncation_psi+(i/frame_count)*pos)\n",
    "pos, neg = trunc_settings.values()\n",
    "\n",
    "# positive\n",
    "# trunc_pos_ws = [G.mapping(a_z, None, truncation_psi=truncation_psi+(i/frame_count)*pos).cpu().numpy() for i in range(1, frame_count+1)]\n",
    "# trunc_pos_ws = torch.from_numpy(np.array(trunc_pos_ws)[:,0,:]).to(device)\n",
    "\n",
    "trunc_neg_ws = [G.mapping(a_z, None, truncation_psi=truncation_psi-(i/frame_count)*neg).cpu().numpy() for i in range(1, frame_count+1)]\n",
    "trunc_neg_ws = torch.from_numpy(np.array(trunc_neg_ws)[:,0,:]).to(device)\n",
    "\n",
    "imgs = generate_images_from_ws(G, trunc_neg_ws, batch_size)\n",
    "fn = 'test.mp4'\n",
    "make_movie(fn, imgs, fps)\n",
    "Video(fn, embed=True, width=800, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2df5d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTS\n",
    "# l = np.load(f'{outdir}/0/1_z.npz')['z']\n",
    "# l = np.array([[1,2,3,4], [2,3,4,6]])\n",
    "# a = np.random.randint(5, size=(4,512))\n",
    "a = np.ones((4,512))\n",
    "l = np.zeros((4,512))\n",
    "# print(l[:, ::2].shape)\n",
    "# l[:, ::2] = 10\n",
    "# l[:, 1::2] = 100\n",
    "# l[:, 2::3] = 1000\n",
    "\n",
    "# x = np.array([1,2,3])\n",
    "# x = np.tile(x, 512//x.shape[0]+1)\n",
    "# x = np.delete(x, 512-x.shape[0])\n",
    "# l[:,0::3] -= x[0::3]\n",
    "# l[:,1::3] += x[1::3]\n",
    "# l[:,2::3] -= x[2::3]\n",
    "# print(l.shape, l[:,:10])\n",
    "a[[1,2,3]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672d8864",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python combine_npz.py --outdir={outdir}/npz --npzs='{outdir}/0/0_w.npz,{outdir}/0/1_w.npz,{outdir}/0/2_w.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1301c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python generate.py \\\n",
    "    --process=interpolation \\\n",
    "    --interpolation=linear \\\n",
    "    --easing=easeInOutQuad \\\n",
    "    --space=w \\\n",
    "    --network={network_pkl} \\\n",
    "    --outdir={outdir}/combined-proj/ \\\n",
    "    --projected-w={outdir}/npz/combined.npz \\\n",
    "    --frames=120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4904ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python generate.py \\\n",
    "    --outdir={outdir}/video-circularloop/ \\\n",
    "    --trunc=1 \\\n",
    "    --process=\"interpolation\" \\\n",
    "    --interpolation=\"circularloop\" \\\n",
    "    --diameter=800.00 \\\n",
    "    --frames=720 \\\n",
    "    --random_seed=90 --network=/content/stylegan2-ada-pytorch/pretrained/wikiart.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6315c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate from Zs\n",
    "# Convert back from np to Torch\n",
    "if isinstance(zs, np.ndarray):\n",
    "    zs = torch.tensor(zs, dtype=torch.float32, device=device)\n",
    "labels = torch.zeros([zs.shape[0], G.c_dim], device=device)\n",
    "all_imgs_from_zs = []\n",
    "for i in range(2):\n",
    "    # Mask latents array using cluster_labels\n",
    "    zs_cluster = zs[cluster_labels==i]\n",
    "    print(zs_cluster.shape)\n",
    "    print(f'Cluster {i}: {zs_cluster.shape[0]} imgs (saving {img_count}, trunc_psi:{truncation_psi}, noise_mode:{noise_mode})')\n",
    "    # Convert back from np to Torch\n",
    "    imgs = generate_images_from_zs(G, device, zs_cluster[:img_count], labels[:img_count], 16, truncation_psi, noise_mode)\n",
    "    all_imgs_from_zs.append(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgs in all_imgs_from_zs:\n",
    "    display(image_grid(imgs, 4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c26cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU mem\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6411a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_size(size):\n",
    "\t\"\"\"Pretty prints a torch.Size object\"\"\"\n",
    "\tassert(isinstance(size, torch.Size))\n",
    "\treturn \" Ã— \".join(map(str, size))\n",
    "\n",
    "def dump_tensors(gpu_only=True):\n",
    "\t\"\"\"Prints a list of the Tensors being tracked by the garbage collector.\"\"\"\n",
    "\timport gc\n",
    "\ttotal_size = 0\n",
    "\tfor obj in gc.get_objects():\n",
    "\t\ttry:\n",
    "\t\t\tif torch.is_tensor(obj):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s:%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t  \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  \" pinned\" if obj.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  pretty_size(obj.size())))\n",
    "\t\t\t\t\ttotal_size += obj.numel()\n",
    "\t\t\telif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s â†’ %s:%s%s%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   type(obj.data).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" pinned\" if obj.data.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" grad\" if obj.requires_grad else \"\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" volatile\" if obj.volatile else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   pretty_size(obj.data.size())))\n",
    "\t\t\t\t\ttotal_size += obj.data.numel()\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tpass        \n",
    "\tprint(\"Total size:\", total_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a8c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8df29d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del image_mean, image_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb49b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "del G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ebea14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sg2ada-pytorch]",
   "language": "python",
   "name": "conda-env-sg2ada-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
